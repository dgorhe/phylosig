{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ete3\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.phylogenetic_signal import PagelsLambda\n",
    "from src.ihmp import get_diffs\n",
    "from src.greengenes import (\n",
    "    parse_similarity_map, merge_otu_table, combine_similarity_maps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download greengenes OTUs dataset, if necessary\n",
    "if ! [ -d greengenes/data/gg_13_5_otus/ ]; then\n",
    "    if ! [ -f greengenes/data/gg_13_5_otus.tar.gz ]; then\n",
    "        wget -O greengenes/data/gg_13_5_otus.tar.gz \\\n",
    "            https://gg-sg-web.s3-us-west-2.amazonaws.com/downloads/greengenes_database/gg_13_5/gg_13_5_otus.tar.gz\n",
    "    fi\n",
    "    tar -xvf greengenes/data/gg_13_5_otus.tar.gz -C greengenes/data/\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I load OTU tables using the basic iHMP scripts from earlier notebooks\n",
    "\n",
    "data = {\n",
    "    name: get_diffs(name, get_abundances=True, log=False) # undo log transform\n",
    "    for name in [\"ibd\", \"moms\", \"t2d\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phil/phylosig/src/greengenes.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_otu_table[cluster_id] = otu_table[existing_otus].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 (98, 1370) 1.000 1.000 1.000\n",
      "94 (98, 1171) 1.000 1.000 1.000\n",
      "91 (98, 799) 1.000 1.000 1.000\n",
      "88 (98, 536) 1.000 1.000 1.000\n",
      "85 (98, 337) 1.000 1.000 1.000\n",
      "82 (98, 203) 1.000 1.000 1.000\n",
      "79 (98, 118) 1.000 1.000 1.000\n",
      "76 (98, 82) 1.000 1.000 1.000\n",
      "73 (98, 43) 1.000 1.000 1.000\n",
      "70 (98, 24) 1.000 1.000 1.000\n",
      "67 (98, 13) 1.000 1.000 1.000\n",
      "64 (98, 8) 1.000 1.000 1.000\n",
      "61 (98, 6) 1.000 1.000 1.000\n"
     ]
    }
   ],
   "source": [
    "# Sanity check 1: relative abundances continue to sum to 1\n",
    "# They do!!!\n",
    "similarity_map99 = parse_similarity_map(99)\n",
    "similarity_map = similarity_map99\n",
    "for x in [97, 94, 91, 88, 85, 82, 79, 76, 73, 70, 67, 64, 61]:\n",
    "    similarity_map = combine_similarity_maps(\n",
    "        [similarity_map, parse_similarity_map(x)]\n",
    "    )\n",
    "    clustered = merge_otu_table(data[\"ibd\"], similarity_map)\n",
    "    s = clustered.sum(axis=1)\n",
    "    print(f\"{x} {clustered.shape} {s.min():.3f} {s.mean():.3f} {s.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ./results/ibd_pls_cutoff99.tsv because it already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phil/phylosig/src/greengenes.py:207: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_otu_table[cluster_id] = otu_table[existing_otus].sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 (98, 1370) 1.000 1.000 1.000\n"
     ]
    }
   ],
   "source": [
    "# Get lambdas for each cutoff\n",
    "\n",
    "# for name in names:\n",
    "#     outpath = f\"./results/{name}_{ab_str}pls_top{TOP_N}.tsv\"\n",
    "#     print(outpath)\n",
    "#     if os.path.exists(outpath):\n",
    "#         print(f\"Skipping {outpath} because it already exists.\")\n",
    "#         continue\n",
    "#     pls, tree = pagels_dataframe(data[name], GG_TREE)\n",
    "#     pls.to_csv(outpath, sep=\"\\t\")\n",
    "#     tree.write(\n",
    "#         format=1, outfile=f\"./results/{name}_{ab_str}tree_top{TOP_N}.nwk\"\n",
    "#     )\n",
    "\n",
    "\n",
    "lambdas = []\n",
    "\n",
    "similarity_map99 = parse_similarity_map(99)\n",
    "similarity_map = similarity_map99\n",
    "for x in [99, 97, 94, 91, 88, 85, 82, 79, 76, 73, 70, 67, 64, 61]:\n",
    "\n",
    "    # Non-redundancy check\n",
    "    outpath = f\"./results/ibd_pls_cutoff{x}.tsv\"\n",
    "    if os.path.exists(outpath):\n",
    "        print(f\"Skipping {outpath} because it already exists.\")\n",
    "        continue\n",
    "\n",
    "    lambdas_cutoff = []\n",
    "\n",
    "    # Get GreenGenes data\n",
    "    if x == 99:\n",
    "        similarity_map = similarity_map99\n",
    "    else:\n",
    "        similarity_map = combine_similarity_maps(\n",
    "            [similarity_map, parse_similarity_map(x)]\n",
    "        )\n",
    "    tree = ete3.Tree(\n",
    "        f\"/home/phil/phylosig/greengenes/data/gg_13_5_otus/trees/{x}_otus.tree\",\n",
    "        format=1,\n",
    "        quoted_node_names=True,\n",
    "    )\n",
    "\n",
    "    # Filter OTU table\n",
    "    clustered = merge_otu_table(data[\"ibd\"], similarity_map)\n",
    "    s = clustered.sum(axis=1)\n",
    "    print(f\"{x} {clustered.shape} {s.min():.3f} {s.mean():.3f} {s.max():.3f}\")\n",
    "\n",
    "    # Filter tree, init PL object\n",
    "    tree.prune(clustered.columns)\n",
    "    pl = PagelsLambda(tree)\n",
    "\n",
    "    # Get lambdas\n",
    "    for sample in tqdm(clustered.index):\n",
    "        pl.fit(clustered.loc[sample])\n",
    "        lambdas_cutoff.append({\"sample\": sample, \"lambda\": pl.lam})\n",
    "    \n",
    "    lambdas_cutoff_df = pd.DataFrame(lambdas_cutoff)\n",
    "    lambdas_cutoff_df.to_table(outpath)\n",
    "\n",
    "    lambdas_cutoff_df[\"cutoff\"] = x\n",
    "    lambdas.append(lambdas_cutoff_df)\n",
    "\n",
    "lambdas_df = pd.concat(lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cluster_lambda = pd.DataFrame(columns=[\"sample\", \"lambda\", \"cutoff\"])\n",
    "for x in [99, 97, 94, 91, 88, 85, 82, 79, 76, 73, 70, 67, 64, 61]:\n",
    "    result = pd.read_table(f\"./results/ibd_pls_cutoff{x}.tsv\")\n",
    "    result[\"cutoff\"] = x\n",
    "    cluster_lambda = cluster_lambda.append(result)\n",
    "\n",
    "# Violin plot for each cutoff\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax = sns.violinplot(\n",
    "    x=\"cutoff\", y=\"lambda\", data=cluster_lambda, ax=ax, inner=\"quartile\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
