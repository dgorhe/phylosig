import pandas as pd
import numpy as np
import ot # type: ignore

from sklearn.preprocessing import LabelEncoder, OrdinalEncoder

from ete3 import Tree # type: ignore
from skbio import TreeNode # type: ignore
from skbio.diversity.beta import weighted_unifrac, unweighted_unifrac # type: ignore

from pdb import set_trace
import os
from io import StringIO
from tqdm import tqdm

# Global variables
ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))


def load_otus(data_path: str, metadata: pd.DataFrame) -> pd.DataFrame:
    ibd_data = pd.read_csv(data_path, dtype={0: str})
    _otus = ibd_data.set_index(ibd_data.columns[3])
    _otus.drop(columns=['patient', 'visit', 'site'], inplace=True)
    otus = _otus.T.copy()
    
    return otus[metadata['sample']].copy()


def load_metadata(metadata_path: str):
    # dianosis: CD = chrons disease, UC = ulcerative colitis, nonIBD = control
    ibd_metadata = pd.read_csv(metadata_path)

    # Drop the nonIBD label since we only have 1 example of it
    non_ibd_index = ibd_metadata[ibd_metadata.diagnosis == "nonIBD"].index.item()
    ibd_metadata.drop(index=non_ibd_index, inplace=True)
    
    return ibd_metadata


def generate_ot_sample_cost_df(cost_matrix: pd.DataFrame, otus: pd.DataFrame) -> pd.DataFrame:
    num_samples = otus.shape[1]
    _sample_cost_matrix = np.zeros((num_samples, num_samples))

    # Calculate the upper triangle of (samples x samples) total cost matrix
    # Each entry is sum of entries in the transport matrix generated by OT
    for i in range(num_samples):
        for j in range(num_samples):
            # The diagonal should have total cost 0 by definition
            if i == j:
                _sample_cost_matrix[i, j] = 0
            if j > i:
                # Create normalized p_i and q_j vectors
                p = otus[otus.columns[i]].to_numpy()
                p_norm = p / p.sum()
                q = otus[otus.columns[j]].to_numpy()
                q_norm = q / q.sum()
                
                # Calculate total cost which is equivalent to the Wasserstein distance
                total_cost = ot.emd2(p_norm, q_norm, cost_matrix, log=False, check_marginals=False)
                
                # Assign the cost to the corresponding entry
                _sample_cost_matrix[i, j] = total_cost
                
    sample_cost_matrix = np.tril(_sample_cost_matrix.T, k=1) + _sample_cost_matrix
    sample_cost_df = pd.DataFrame(sample_cost_matrix, index=otus.columns, columns=otus.columns)
    
    return sample_cost_df


def generate_unifrac_df(otus: pd.DataFrame, tree: TreeNode, _type: str) -> pd.DataFrame:
    assert _type == "weighted" or _type == "unweighted"
    
    # Calculating the Unweighted UniFrac cost matrix
    COLUMNS = otus.columns
    unifrac_cost_matrix = np.zeros((len(COLUMNS), len(COLUMNS)))
    taxa = otus.index.to_list()
    progress_bar = tqdm(enumerate(COLUMNS), total=len(COLUMNS))

    for i, sample_i in progress_bar:
        for j, sample_j in enumerate(COLUMNS):
            if i <= j:
                unifrac_cost_matrix[i, j] = 0
            if i > j:    
                u_counts = otus[sample_i].values.copy()
                v_counts = otus[sample_j].values.copy()
                
                if _type == "unweighted":
                    val = unweighted_unifrac(u_counts=u_counts,
                                            v_counts=v_counts,
                                            taxa=taxa,
                                            tree=tree)
                elif _type == "weighted":
                    val = weighted_unifrac(u_counts=u_counts,
                                            v_counts=v_counts,
                                            taxa=taxa,
                                            tree=tree)
                
                unifrac_cost_matrix[i, j] = val

    return pd.DataFrame(unifrac_cost_matrix, index=COLUMNS, columns=COLUMNS)


def generate_metadata_df(metadata: pd.DataFrame, columns=None) -> pd.DataFrame:
    if metadata.index.name != "sample":
        if columns is None:
            metadata_columns_categorical = [#"Bowel frequency during the day",
                                            "Soft drinks, tea or coffee with sugar (corn syrup, maple syrup, cane sugar, etc)",
                                            "Diet soft drinks, tea or coffee with sugar (Stevia, Equal, Splenda etc)",
                                            "Antibiotics",
                                            "Occupation",
                                            "Specify race",
                                            "sex",
                                            "sample"]
        else:
            metadata_columns_categorical = columns

        _subset_metadata_df = metadata[metadata_columns_categorical].set_index("sample")
    else:
        if columns is None:
            metadata_columns_categorical = [#"Bowel frequency during the day",
                                            "Soft drinks, tea or coffee with sugar (corn syrup, maple syrup, cane sugar, etc)",
                                            "Diet soft drinks, tea or coffee with sugar (Stevia, Equal, Splenda etc)",
                                            "Antibiotics",
                                            "Occupation",
                                            "Specify race",
                                            "sex"]
        else:
            metadata_columns_categorical = columns

        _subset_metadata_df = metadata[metadata_columns_categorical]
        

    enc = OrdinalEncoder(encoded_missing_value=10)
    encoded_metadata = enc.fit_transform(_subset_metadata_df)

    encoded_metadata_df = pd.DataFrame(encoded_metadata,
                                       index=_subset_metadata_df.index,
                                       columns=_subset_metadata_df.columns)
    
    return encoded_metadata_df


if __name__ == "__main__":
    # Load input data
    metadata = load_metadata(metadata_path="ihmp/ibd_metadata_new.csv")
    # otus = load_otus(data_path="ihmp/ibd_data.csv", metadata=metadata)
    # tree = Tree("data/gg_13_5_otus_99_annotated.tree", format=1, quoted_node_names=True)
    # skbio_tree = TreeNode.read(StringIO(tree.write(format_root_node=True))) # type: ignore
    # skbio_subtree = skbio_tree.shear(otus.index)

    metadata_reference_df = generate_metadata_df(metadata=metadata)
    set_trace()
    
    # ## OT Cost Matrices ##
    # ot_cost_matrix_paths = [f"{ROOT}/levenshtein_cost_matrix.npy",
    #                         f"{ROOT}/alignment_cost_matrix.npy"]
    
    # input_cost_matrices = {}
    # sample_cost_matrices = {}
    
    # for cost_matrix_path in ot_cost_matrix_paths:
    #     name = cost_matrix_path.split("/")[-1].split("_")[0]
    #     print(name)
        
    #     with open(cost_matrix_path, "rb") as file_in:
    #         cost_matrix = np.load(file_in)
       
    #     input_cost_matrices[name] = cost_matrix
    #     sample_cost_matrices[name] = generate_ot_sample_cost_df(cost_matrix=cost_matrix,
    #                                                             otus=otus)
    
    # ## UniFrac Reference ##
    # print("unweighted unifrac")
    # unweighted_unifrac_df = generate_unifrac_df(otus, skbio_subtree, _type="unweighted")
    
    # print("weighted unifrac")
    # weighted_unifrac_df = generate_unifrac_df(otus, skbio_subtree, _type="weighted")