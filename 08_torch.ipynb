{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Switching to PyTorch\n",
    "> Comparing the performance of PyTorch and NumPy based Pagels lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# All the imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ete3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stuff for timing\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# My stuff\n",
    "from src.ihmp import get_diffs\n",
    "from src.phylogenetic_signal_torch import PagelsLambda as PagelsLambdaTorch\n",
    "from src.phylogenetic_signal import PagelsLambda as PagelsLambdaNumpy\n",
    "\n",
    "treepath = \"greengenes/data/gg_13_5_otus_99_annotated.tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1000269</th>\n",
       "      <th>1008348</th>\n",
       "      <th>1009894</th>\n",
       "      <th>1012376</th>\n",
       "      <th>1017181</th>\n",
       "      <th>1017413</th>\n",
       "      <th>1019823</th>\n",
       "      <th>1019878</th>\n",
       "      <th>102222</th>\n",
       "      <th>1023075</th>\n",
       "      <th>...</th>\n",
       "      <th>964363</th>\n",
       "      <th>968675</th>\n",
       "      <th>968954</th>\n",
       "      <th>971907</th>\n",
       "      <th>975306</th>\n",
       "      <th>976470</th>\n",
       "      <th>979707</th>\n",
       "      <th>988375</th>\n",
       "      <th>988932</th>\n",
       "      <th>999046</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th>patient</th>\n",
       "      <th>visit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">feces</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">3002</th>\n",
       "      <th>6</th>\n",
       "      <td>-10.298141</td>\n",
       "      <td>-10.991272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.68441</td>\n",
       "      <td>11.70451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028690</td>\n",
       "      <td>-2.331253</td>\n",
       "      <td>-12.244023</td>\n",
       "      <td>-1.152620</td>\n",
       "      <td>-11.396731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.059309</td>\n",
       "      <td>1.224061</td>\n",
       "      <td>-10.298141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-11.70451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.704510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.313941</td>\n",
       "      <td>-10.605914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.557134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.215332</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.83337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.219649</td>\n",
       "      <td>11.526507</td>\n",
       "      <td>10.833370</td>\n",
       "      <td>14.704551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.526507</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3003</th>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.768101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.026190</td>\n",
       "      <td>11.768101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1000269    1008348  1009894  1012376   1017181  \\\n",
       "site  patient visit                                                     \n",
       "feces 3002    6     -10.298141 -10.991272      0.0      0.0 -11.68441   \n",
       "              8       0.000000   0.000000      0.0      0.0   0.00000   \n",
       "              9       0.000000   0.000000      0.0      0.0   0.00000   \n",
       "      3003    5       0.000000   0.000000      0.0      0.0   0.00000   \n",
       "              6       0.000000   0.000000      0.0      0.0   0.00000   \n",
       "\n",
       "                      1017413  1019823    1019878  102222  1023075  ...  \\\n",
       "site  patient visit                                                 ...   \n",
       "feces 3002    6      11.70451      0.0   0.307779     0.0      0.0  ...   \n",
       "              8     -11.70451      0.0 -11.704510     0.0      0.0  ...   \n",
       "              9      10.83337      0.0   0.000000     0.0      0.0  ...   \n",
       "      3003    5       0.00000      0.0   0.000000     0.0      0.0  ...   \n",
       "              6       0.00000      0.0   0.000000     0.0      0.0  ...   \n",
       "\n",
       "                     964363     968675     968954     971907     975306  \\\n",
       "site  patient visit                                                       \n",
       "feces 3002    6         0.0  -0.028690  -2.331253 -12.244023  -1.152620   \n",
       "              8         0.0 -13.313941 -10.605914   0.000000 -14.557134   \n",
       "              9         0.0  12.219649  11.526507  10.833370  14.704551   \n",
       "      3003    5         0.0   0.000000   0.000000   0.000000   0.000000   \n",
       "              6         0.0  11.768101   0.000000   0.000000   0.000000   \n",
       "\n",
       "                        976470  979707     988375     988932     999046  \n",
       "site  patient visit                                                      \n",
       "feces 3002    6     -11.396731     0.0 -14.059309   1.224061 -10.298141  \n",
       "              8       0.000000     0.0   0.000000 -12.215332   0.000000  \n",
       "              9       0.000000     0.0   0.000000  11.526507   0.000000  \n",
       "      3003    5       0.000000     0.0   0.000000   0.000000   0.000000  \n",
       "              6       0.000000     0.0  15.026190  11.768101   0.000000  \n",
       "\n",
       "[5 rows x 1370 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data and prune tree appropriately\n",
    "\n",
    "ibd = get_diffs(\"ibd\")\n",
    "\n",
    "tree = ete3.Tree(treepath, format=1, quoted_node_names=True)\n",
    "leaves = ibd.columns\n",
    "tree.prune(leaves)\n",
    "\n",
    "ibd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to initialize PagelsLambdaTorch: 70.47 seconds\n"
     ]
    }
   ],
   "source": [
    "# Time initialization - this is probably not the slowest part of the code\n",
    "# At least you only have to do it once\n",
    "\n",
    "t1 = time.time()\n",
    "pl_torch = PagelsLambdaTorch(tree)\n",
    "t2 = time.time()\n",
    "print(f\"Time to initialize PagelsLambdaTorch: {t2-t1:.2f} seconds\")\n",
    "\n",
    "# pl_numpy = PagelsLambdaNumpy(tree)\n",
    "# t3 = time.time()\n",
    "# print(f\"Time to initialize PagelsLambdaNumpy: {t3-t2:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [00:25<03:51, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03923378139734268 tensor([[4240.7456]], grad_fn=<NegBackward0>)\n",
      "0.15255992114543915 tensor([[4230.9814]], grad_fn=<NegBackward0>)\n",
      "0.15255992114543915 tensor([[4227.0430]], grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 2/10 [01:15<05:00, 37.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intel MKL ERROR: Parameter 4 was incorrect on entry to SLASCL.\n",
      "\n",
      "Intel MKL ERROR: Parameter 4 was incorrect on entry to SLASCL.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "_LinAlgError",
     "evalue": "linalg.svd: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 20).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_LinAlgError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/phil/phylosig/08_torch.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/phylosig/08_torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m torch_lams \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/phylosig/08_torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/phylosig/08_torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     pl_torch\u001b[39m.\u001b[39;49mfit(ibd_torch[i])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/phylosig/08_torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     torch_lams\u001b[39m.\u001b[39mappend(pl_torch\u001b[39m.\u001b[39mlam)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beumaeus/home/phil/phylosig/08_torch.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m t2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/phylosig/src/phylogenetic_signal_torch.py:80\u001b[0m, in \u001b[0;36mPagelsLambda.fit\u001b[0;34m(self, x, y, max_iterations, tolerance, unbiased)\u001b[0m\n\u001b[1;32m     77\u001b[0m prev_loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iterations):\n\u001b[0;32m---> 80\u001b[0m     loss \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mstep(closure)\n\u001b[1;32m     81\u001b[0m     \u001b[39m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39m# loss = neg_ll(lam_tensor)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[39m# loss.backward()\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(prev_loss \u001b[39m-\u001b[39m loss) \u001b[39m<\u001b[39m tolerance:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    424\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 426\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[39m=\u001b[39m _strong_wolfe(\n\u001b[1;32m    427\u001b[0m         obj_func, x_init, t, d, loss, flat_grad, gtd)\n\u001b[1;32m    428\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    429\u001b[0m opt_cond \u001b[39m=\u001b[39m flat_grad\u001b[39m.\u001b[39mabs()\u001b[39m.\u001b[39mmax() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m tolerance_grad\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:148\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m    145\u001b[0m     insuf_progress \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m# Evaluate new point\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m f_new, g_new \u001b[39m=\u001b[39m obj_func(x, t, d)\n\u001b[1;32m    149\u001b[0m ls_func_evals \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    150\u001b[0m gtd_new \u001b[39m=\u001b[39m g_new\u001b[39m.\u001b[39mdot(d)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:424\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_directional_evaluate(closure, x, t, d)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/optim/lbfgs.py:278\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_directional_evaluate\u001b[39m(\u001b[39mself\u001b[39m, closure, x, t, d):\n\u001b[1;32m    277\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m--> 278\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(closure())\n\u001b[1;32m    279\u001b[0m     flat_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    280\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_param(x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/phylosig/src/phylogenetic_signal_torch.py:65\u001b[0m, in \u001b[0;36mPagelsLambda.fit.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m():\n\u001b[1;32m     64\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m     loss \u001b[39m=\u001b[39m neg_ll(lam_tensor)\n\u001b[1;32m     66\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     67\u001b[0m     \u001b[39m# print(\"Gradients:\", lam_tensor.grad)\u001b[39;00m\n",
      "File \u001b[0;32m~/phylosig/src/phylogenetic_signal_torch.py:60\u001b[0m, in \u001b[0;36mPagelsLambda.fit.<locals>.neg_ll\u001b[0;34m(lam)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mneg_ll\u001b[39m(lam):\n\u001b[1;32m     59\u001b[0m     C_lam \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrescale_cov(lam, cov\u001b[39m=\u001b[39mC)\n\u001b[0;32m---> 60\u001b[0m     z0, sigma2, ll \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmle(x, C_lam, unbiased\u001b[39m=\u001b[39;49munbiased)\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mll\n",
      "File \u001b[0;32m~/phylosig/src/phylogenetic_signal_torch.py:138\u001b[0m, in \u001b[0;36mPagelsLambda.mle\u001b[0;34m(self, x, C_lam, unbiased)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mEstimate z0 and sigma2 for Brownian motion, plus log-likelihood.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m    ll: log-likelihood of the data given the model\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    136\u001b[0m N \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x)\n\u001b[0;32m--> 138\u001b[0m C_inv \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mpinv(C_lam)\n\u001b[1;32m    140\u001b[0m \u001b[39m# First, get z0\u001b[39;00m\n\u001b[1;32m    141\u001b[0m one \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(size\u001b[39m=\u001b[39m(N, \u001b[39m1\u001b[39m))\n",
      "\u001b[0;31m_LinAlgError\u001b[0m: linalg.svd: The algorithm failed to converge because the input matrix is ill-conditioned or has too many repeated singular values (error code: 20)."
     ]
    }
   ],
   "source": [
    "# Free preprocessing: turn df into Tensor\n",
    "\n",
    "ibd_torch = torch.tensor(ibd.values, dtype=torch.float32)\n",
    "\n",
    "t1 = time.time()\n",
    "torch_lams = []\n",
    "for i in tqdm(range(10)):\n",
    "    pl_torch.fit(ibd_torch[i])\n",
    "    torch_lams.append(pl_torch.lam)\n",
    "t2 = time.time()\n",
    "print(f\"Time to fit PagelsLambdaTorch: {t2-t1:.2f} seconds\")\n",
    "\n",
    "# np_lams = []\n",
    "# for idx in tqdm(range(10)):\n",
    "#     pl_numpy.fit(ibd.iloc[idx].values)\n",
    "#     np_lams.append(pl_numpy.lam)\n",
    "# t3 = time.time()\n",
    "# print(f\"Time to fit PagelsLambdaNumpy: {t3-t2:.2f} seconds\")\n",
    "\n",
    "# # Compare results\n",
    "# diffs = np.array(torch_lams) - np.array(np_lams)\n",
    "# print(f\"Total difference: {np.sum(diffs):.2f}\")\n",
    "print(np.array(torch_lams))\n",
    "# print(np.array(np_lams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
